###########################################################################################
####                                                                                  #####
####                                    WARNING                                       #####
#### Do not delete any field, if you want delete debug level for log, set it to false #####
####                                                                                  #####
###########################################################################################
[openstack_orchestrator]
# Set 0.0.0.0 to listen on all addresses
ip = 0.0.0.0
# TCP port used by the OS-DO for receiving commands through its rest API
port = 9200

# IP address where Openstack can be reached
openstack_ip = 192.168.10.173

# Specify where VNF instances have to be instantiated
# Remove this line if you want to leave this choice to the OpenStack scheduler
availability_zone = my_az

# Set the Keystone API version that the openstack orchestrator should use to contact OpenStack. Starting from Mitaka version, v2 APIs have been deprecated.
# This value can be 2 or 3 
identity_api_version = 3

# Timeout after that the domain orchestrator will stop waiting for a response (in seconds)
timeout = 90

[authentication]
token_expiration = 86400

[jolnet]
# If you are using this domain orchestrator in the JOLNet environment set to true the following option
#    and set also the 'jolnet_networks' field
# Finally, remember that, in case the controlled OpenStack domain is older than Mitaka, you have
#    to set also identity_api_version = 2 in the general configuration section.
jolnet_mode = false
# List of the networks that have to be used while instantiating VNFs in JOLNet. If you don't have this scenario you can comment out the following line
#jolnet_networks = exp280, exp281, exp282, exp283, exp284, exp285, exp286, exp287, exp288, exp289, exp290, exp291, exp292, exp293, exp294, exp295, exp296, exp297, exp298, exp299

[topology]
# Virtual switch where virtual machines are connected
integration_bridge = br-int

# virtual switch responsible for the user outgoing traffic
exit_switch = br-ex

[onos]
# IP address of the node where ONOS is running. ( respect this format: http://<IP_ADDRESS>:8181 )
address  = http://192.168.20.173:8181
username = onos
password = rocks
#Set this variable to true or false. If it's false the default behaviour is to use ODL
enabled  = true
onos_integration_bridge_local_ip = 192.168.20.173

[odl]
address  = 192.168.21:8181
username = admin
password = admin
integration_bridge_local_ip = http://127.0.0.1/

[doubledecker]
dd_name = openstack_orchestrator
dd_customer = public
broker_address = tcp://127.0.0.1:5555
dd_keyfile = config/public-keys.json

[domain_description]
topic = frog:domain-description
file = ./config/ResourceDescriptions/ResourceDescription.json

[log]
# Location of the log file
log_file=OpenstackOrchestrator.log

# Log levels
verbose_level = true
# with this mode the DO will print all flows within a file
debug_mode = true

[db]
# Mysql DB
connection = mysql+pymysql://orch-user:orch-pwd@127.0.0.1:3306/openstack_orchestrator

[templates]
# Define the source where the templates can be achieved. This source can be 'datastore'
# or 'file' (that identify the file system)
#source = file
source = datastore

# This is considered in case source=file
path = templates/

# This is considered in case source=datastore
# Define the url where the templates will be requested
datastore_url = http://127.0.0.1:8081/v2/
